library(gamlss.add)
install.packages("gamlss.add")
library(gamlss.add)
data<-read.csv2("bank.csv")
#Transformation de y en variable bianire :
data$y = recode(data$y, "no" = 0, "yes" = 1)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(glmnet)
library(caTools)
#Transformation de y en variable bianire :
data$y = recode(data$y, "no" = 0, "yes" = 1)
#Echantillonage des données
ech = sort(sample(nrow(data), nrow(data)*.7))
train = data[ech, ]
test = data[-ech, ]
#Definition variables explicatives/variable cible
Xtrain = train[, -17]
ytrain = train[, 17]
Xtest = test[, -17]
ytest = test[, 17]
summary(train)
model <- nnet(y=ytrain, x=Xtrain, size = 10,)
model <- nnet(y=ytrain, x=Xtrain, size = 10)
data$y
ytrain
Xtrain
nnet(y=ytrain, x=Xtrain, size = 10)
model <- nnet(ytrain~., data=train, size = 10)
plot(model)
plot(model,nid=F)
pred <- predict(model, newdata = test)
table(pred)
plot.nnet(model,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
plot.nnet(model,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
plot(model,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
model <- nnet(ytrain~., data=train, size = 10,decay=5e-4, maxit=200)
pred <- predict(model, newdata = test)
table(pred)
model <- nnet(ytrain~., data=train, size = 10,decay=5e-4, maxit=200, linout=FALSE)
pred <- predict(model, newdata = test)
table(pred)
m<-table(pred,test)
m<-table(pred,ytest)
m
df<-read.xlsx2("BDD_CEDA_dec_2020_complete - ANONYME.xlsx", sheetIndex = 1,header = TRUE)
library(xlsx)
df<-read.xlsx2("BDD_CEDA_dec_2020_complete - ANONYME.xlsx", sheetIndex = 1,header = TRUE)
#source
preoccupation_source=VectorSource(df$Préoccupations)
library(tm)
library(ngram)
library(wordcloud)
BigramTokenizer =function(x){
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
}
OnegramTokenizer =function(x){
unlist(lapply(ngrams(words(x), 1), paste, collapse = " "), use.names = FALSE)
}
#source
preoccupation_source=VectorSource(df$Préoccupations)
#corpus
preoccupation_corpus=VCorpus(preoccupation_source)
#TransformMinuscule
preoccupation_corpus= tm_map(preoccupation_corpus,content_transformer(tolower))
#removePunctuation
preoccupation_corpus = tm_map(preoccupation_corpus,removePunctuation)
#removeStopWord
preoccupation_corpus = tm_map(preoccupation_corpus,removeWords, stopwords('fr'))
#removeWhiteSpace
preoccupation_corpus = tm_map(preoccupation_corpus,stripWhitespace)
preoccupation_matrix=TermDocumentMatrix(preoccupation_corpus, control = list(tokenize=BigramTokenizer))
#matrice
M_preoccupation <- as.matrix(preoccupation_matrix)
print(nrow(M_preoccupation))
print(ncol(M_preoccupation))
#liste des termes
#print(colnames(M1))
#fréquence de chaque terme
freq_preoccupation <- apply(M_preoccupation,1,sum)
print(sort(freq_preoccupation,decreasing=TRUE)[1:10])
wordcloud(names(freq_preoccupation),freq_preoccupation,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
wordcloud(names(freq_preoccupation),freq_preoccupation,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
preoccupation_matrix2=TermDocumentMatrix(preoccupation_corpus, control = list(tokenize=OnegramTokenizer))
#matrice
M_preoccupation2 <- as.matrix(preoccupation_matrix2)
print(nrow(M_preoccupation2))
print(ncol(M_preoccupation2))
#liste des termes
#print(colnames(M1))
#fréquence de chaque terme
freq_preoccupation2 <- apply(M_preoccupation2,1,sum)
print(sort(freq_preoccupation2,decreasing=TRUE)[1:10])
wordcloud(names(freq_preoccupation2),freq_preoccupation2,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
wordcloud(names(freq_preoccupation2),freq_preoccupation2,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
wordcloud(names(freq_preoccupation),freq_preoccupation,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
wordcloud(names(freq_preoccupation),freq_preoccupation,max.words=20,color=c("lightblue3","lightblue4","darkcyan"))
